{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "vg6vxoxx4kzpwv4tatxy",
   "authorId": "322325853055",
   "authorName": "CROMANO",
   "authorEmail": "chase.romano@snowflake.com",
   "sessionId": "e6b8ec43-a585-4776-b8dd-2729eb276724",
   "lastEditTime": 1746820135983
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "1346ac9c-b21f-44fd-b6a1-70de9924cae4",
   "metadata": {
    "language": "python",
    "name": "pip_install",
    "collapsed": false,
    "resultHeight": 306,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Not neccessary since these packages come with the runtime\n#!pip install xgboost snowflake-ml-python ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "imports",
    "collapsed": false,
    "resultHeight": 0
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom snowflake.ml.registry import Registry\nimport ast\n#add another package\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "56066407-bba0-4d10-98f5-2f6dae0145d3",
   "metadata": {
    "language": "python",
    "name": "get_data",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "titanic = pd.read_csv('titanic_snowflake.csv')\ntitanic = titanic.drop([\"AGE\", \n                        \"DECK\", \n                        \"ALIVE\",\n                        \"ADULT_MALE\",\n                        \"EMBARKED\",\n                        \"PCLASS\",\n                        \"ALONE\",\n                        \"SEX\"],axis=1)\ntitanic.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4e117fbf-2fc7-444c-a99a-21b6a1aaffac",
   "metadata": {
    "language": "python",
    "name": "write_to_table"
   },
   "outputs": [],
   "source": "# The next two cells are optional\n# This is showing if your data is already in snowflake how to \n# turn it into a pandas dataframe\n\n\n# This step turns pandas -> snowpark and writes to snowflake\ntitanic_sf = session.create_dataframe(titanic)\ntitanic_sf.write.mode(\"overwrite\").save_as_table(\"titanic_raw\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0b684830-9d7b-4cce-842d-ebcb061935a3",
   "metadata": {
    "language": "python",
    "name": "query_table_snowpark_df"
   },
   "outputs": [],
   "source": "# Here we read a table from Snowflake into a Snowpark dataframe\n\ntitanic_raw = session.table('titanic_raw')\ntitanic_raw.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d04ed79-3389-429f-8352-94b416d6e12f",
   "metadata": {
    "language": "sql",
    "name": "titanic_sql"
   },
   "outputs": [],
   "source": "Select * from titanic_raw;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "07e4da98-62ed-4119-8545-75d0250dbd9b",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": "table  = 'titanic_raw'\n\ndf_demo = session.sql(\nf'''\nSelect * from {table};\n'''\n).to_pandas()\ndf_demo",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5dd9f339-f494-4f79-a1fb-c0c4eb773037",
   "metadata": {
    "language": "python",
    "name": "query_table_pandas_df"
   },
   "outputs": [],
   "source": "# Here we read a table from Snowflake into a Pandas dataframe\n\ntitanic_raw = session.table('titanic_raw').to_pandas()\ntitanic_raw.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8a8bb52d-2b0d-45ff-aa1d-a8df0bbb127b",
   "metadata": {
    "language": "python",
    "name": "drop_nulls",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "titanic.dropna(inplace=True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bb1acb42-85cd-4fc2-a1e6-edcc5704ec45",
   "metadata": {
    "language": "python",
    "name": "get_dummies",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "titanic = pd.get_dummies(titanic, drop_first=True)\n\n# Convert all boolean columns to integers\ntitanic = titanic.apply(lambda x: x.astype(int) if x.dtype == 'bool' else x)\n\ntitanic.dtypes",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fab08374-e406-4a7c-9912-9a92567f5c74",
   "metadata": {
    "language": "python",
    "name": "x_y",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "#now we will get the train data and label\nx = titanic.drop('SURVIVED',axis=1)\ny = titanic.SURVIVED",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "96a8ccdf-943d-4530-9458-f68f93b96dd6",
   "metadata": {
    "language": "python",
    "name": "split_test_train",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "xtrain,xtest,ytrain,ytest = train_test_split(x,y,train_size=.85,random_state=1234)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "544a1c2f-3a07-46e5-a3ee-f72c792fe7ea",
   "metadata": {
    "language": "python",
    "name": "param_grid_def",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "param_grid = {\n    \"n_estimators\": [100, 200],\n    \"learning_rate\": [0.1, 0.5],\n    \"max_depth\": [1,2,3,4,5,6],\n    \"min_child_weight\": [1, 6]\n}",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "84958eaf-df33-48ba-baa9-14659c493135",
   "metadata": {
    "language": "python",
    "name": "train_model",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "model = XGBClassifier(objective='binary:logistic', \n                      eval_metric='logloss')\n\ngrid_search = GridSearchCV(estimator=model, \n                           param_grid=param_grid)\n\ngrid_search.fit(xtrain, ytrain)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9597a1b5-fa80-482b-9279-96dc72020697",
   "metadata": {
    "language": "python",
    "name": "get_best_params",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "# Best parameters and score\nbest_params = grid_search.best_params_\nbest_score = grid_search.best_score_\nprint(\"Best Parameters:\", best_params)\nprint(\"Best Score:\", best_score)\n\n# Evaluate the best model on the test set\nbest_model = grid_search.best_estimator_\ntest_score = best_model.score(xtest, ytest)\nprint(\"Test Score:\", test_score)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f0e53e21-e9d6-453d-8149-448270476258",
   "metadata": {
    "language": "python",
    "name": "show_metrics",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "metrics = {\n    \"Accuracy\": best_score,\n    \"Params\": best_params\n}\n\nmetrics",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "91f97d72-8976-4d03-a92d-bca02010611c",
   "metadata": {
    "language": "python",
    "name": "pickle_model"
   },
   "outputs": [],
   "source": "# import pickle\n\n# MY_STAGE = 'ML_STAGE'\n# MY_FILE_NAME = \"model.pkl\"\n \n# pickle.dump(best_model, open('model.pkl','wb'))\n\n# # Upload the file to a stage.\n# put_result = session.file.put(MY_FILE_NAME, MY_STAGE, auto_compress=False,overwrite=True)\n# put_result[0].status",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6cbdd0b2-65c8-44ec-a70d-fb34af685c7b",
   "metadata": {
    "language": "python",
    "name": "unpickle"
   },
   "outputs": [],
   "source": "# from pickle import load\n\n# model_pkl = session.file.get(\"@ML_STAGE/model.pkl\",\"titanic_cr\")\n\n# #deserialize (unpickle) the model to use on a new data set\n# titanic_pkl=load(open('model.pkl','rb'))",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "87e737c6-902d-42eb-b1ff-9b9793ba8ee3",
   "metadata": {
    "language": "python",
    "name": "register_pkl_model"
   },
   "outputs": [],
   "source": "from snowflake.ml.registry import Registry\n\n# Get sample input data to pass into the registry logging function\nX = xtrain.sample(n=1)\n\n# Create a registry and log the model\n# You can specify a different DB and Schema if you'd like\n# otherwise it uses the session context\n# If a registry does not exist it will create one\nreg = Registry(session=session)\n\n# Define model name and version (use uppercase for name)\nmodel_name = \"TITANIC\"\n\ntitanic_model = reg.log_model(\n    model_name=model_name,\n    options = {\n    \"relax_version\": True,\n    },\n    target_platforms=[\"WAREHOUSE\", \"SNOWPARK_CONTAINER_SERVICES\"],\n    #version_name=\"V_1\", # If you leave version_name off SF creates one\n    model=best_model,\n    sample_input_data=X,\n    metrics=metrics,\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b263614f-9d84-463f-a37d-f4b787889ec4",
   "metadata": {
    "language": "python",
    "name": "register_model",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "from snowflake.ml.registry import Registry\n\n# Get sample input data to pass into the registry logging function\nX = xtrain.sample(n=1)\n\n# Create a registry and log the model\n# You can specify a different DB and Schema if you'd like\n# otherwise it uses the session context\n# If a registry does not exist it will create one\nreg = Registry(session=session)\n\n# Define model name and version (use uppercase for name)\nmodel_name = \"TITANIC\"\n\ntitanic_model = reg.log_model(\n    model_name=model_name,\n    options = {\n    \"relax_version\": True,\n    },\n    target_platforms=[\"WAREHOUSE\", \"SNOWPARK_CONTAINER_SERVICES\"],\n    #version_name=\"V_1\", # If you leave version_name off SF creates one\n    model=best_model,\n    sample_input_data=X,\n    metrics=metrics,\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "18c5b6b9-9b81-4671-b3a2-4d23d437023e",
   "metadata": {
    "language": "python",
    "name": "show_models",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "models_df = reg.show_models()\nmodels_df[models_df['name'] == model_name]",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5538ef69-e58c-4c1d-8af0-3c99c0e9f14e",
   "metadata": {
    "language": "python",
    "name": "show_model_versions",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "models = reg.get_model(model_name).show_versions()\nmodels.sort_values(by='created_on', ascending=False)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ecc5e12f-81b5-421d-91a9-5ae55e48b2c7",
   "metadata": {
    "language": "python",
    "name": "show_recent_model"
   },
   "outputs": [],
   "source": "recent_model_name = models.sort_values('created_on', ascending=False).iloc[0]['name']\nprint(recent_model_name)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "774fde38-6f47-4919-8eca-19619f1a8818",
   "metadata": {
    "language": "python",
    "name": "promote_model",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "m = reg.get_model(model_name)\nm.default = recent_model_name\nmv = m.default\nmv.version_name",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "51a69210-dc84-4d01-b079-dd726b288c31",
   "metadata": {
    "language": "python",
    "name": "predict_remotely",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "remote_prediction = mv.run(xtest, function_name=\"PREDICT_PROBA\")\nremote_prediction.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "75c919f2-8069-4dcf-9cff-999f9815602f",
   "metadata": {
    "language": "python",
    "name": "write_test_to_SF",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "test_sf = session.create_dataframe(xtest)\ntest_sf.write.mode(\"overwrite\").save_as_table(\"test_pd\")\nsession.table('test_pd').show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3dc30d16-9d73-4ee5-94b5-d0320be4851d",
   "metadata": {
    "language": "python",
    "name": "Create_table"
   },
   "outputs": [],
   "source": "titanic_sf = session.create_dataframe(xtest)\ntitanic_sf.write.mode(\"overwrite\").save_as_table(\"titanic_predict\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "beb2ed35-07bb-4ba3-b209-32a25fb01e72",
   "metadata": {
    "language": "sql",
    "name": "predict_with_sql",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "select *, round(TITANIC!predict_proba(*):output_feature_0,2)\nas surv_pred\nfrom titanic_predict",
   "execution_count": null
  }
 ]
}